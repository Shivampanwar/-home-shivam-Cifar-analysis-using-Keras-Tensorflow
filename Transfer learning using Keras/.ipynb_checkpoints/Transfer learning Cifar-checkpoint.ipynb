{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  keras\n",
    "from  keras.datasets  import cifar10\n",
    "import numpy as np\n",
    "#from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "import scipy\n",
    "from scipy import misc\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be downloaded from https://d17h27t6h515a5.cloudfront.net/topher/2016/November/5834b432_vgg-100/vgg-100.zip\n",
    "Make a virtual environment having Python 3 and do as (train.p and  val.p are train and val files respectively) :\n",
    "\n",
    "import pickle\n",
    "with open(\"train.p\", \"rb\") as f:\n",
    "    w = pickle.load(f)\n",
    "pickle.dump(w, open(\"train.pkl\",\"wb\"), protocol=2)\n",
    "with open(\"val.p\", \"rb\") as f:\n",
    "    v = pickle.load(f)\n",
    "pickle.dump(v, open(\"val.pkl\",\"wb\"), protocol=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading bottleneck features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_bottleneck_data(training_file, validation_file):\n",
    "    f = open(training_file, 'r')   # 'r' for reading; can be omitted\n",
    "    train_data = pickle.load(f)         # load file content as mydict\n",
    "    f.close()\n",
    "    g= open(validation_file, 'r')   # 'r' for reading; can be omitted\n",
    "    validation_data = pickle.load(g)         # load file content as mydict\n",
    "    g.close() \n",
    "    X_train = train_data['features']\n",
    "    y_train = train_data['labels']\n",
    "    X_val = validation_data['features']\n",
    "    y_val = validation_data['labels']\n",
    "    return X_val, y_val,X_train, y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is (10000, 1, 1, 512)\n",
      "Y_train shape is (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val=load_bottleneck_data('train.pkl','val.pkl')\n",
    "print \"X_train shape is \"+str(X_train.shape)\n",
    "print \"Y_train shape is \"+str(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes are 10\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "print \"Num classes are \"+str(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 1.7431 - acc: 0.5038 - val_loss: 0.9653 - val_acc: 0.6865\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.96531, saving model to model.best.hdf5\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.7803 - acc: 0.7342 - val_loss: 0.7414 - val_acc: 0.7605\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.96531 to 0.74144, saving model to model.best.hdf5\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.5968 - acc: 0.7976 - val_loss: 0.6509 - val_acc: 0.7855\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.74144 to 0.65086, saving model to model.best.hdf5\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.5038 - acc: 0.8292 - val_loss: 0.6178 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.65086 to 0.61782, saving model to model.best.hdf5\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.4545 - acc: 0.8456 - val_loss: 0.5844 - val_acc: 0.8075\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.61782 to 0.58442, saving model to model.best.hdf5\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.4097 - acc: 0.8590 - val_loss: 0.5620 - val_acc: 0.8115\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.58442 to 0.56204, saving model to model.best.hdf5\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.3779 - acc: 0.8711 - val_loss: 0.5721 - val_acc: 0.8065\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.56204\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.3537 - acc: 0.8769 - val_loss: 0.5418 - val_acc: 0.8215\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.56204 to 0.54184, saving model to model.best.hdf5\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.3341 - acc: 0.8834 - val_loss: 0.5495 - val_acc: 0.8210\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.54184\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.3164 - acc: 0.8896 - val_loss: 0.5381 - val_acc: 0.8285\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.54184 to 0.53809, saving model to model.best.hdf5\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.3002 - acc: 0.8972 - val_loss: 0.5507 - val_acc: 0.8220\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.53809\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.2878 - acc: 0.8990 - val_loss: 0.5518 - val_acc: 0.8225\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.53809\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.2737 - acc: 0.9055 - val_loss: 0.5404 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.53809\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.2687 - acc: 0.9095 - val_loss: 0.5522 - val_acc: 0.8245\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.53809\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.2536 - acc: 0.9189 - val_loss: 0.5472 - val_acc: 0.8235\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.53809\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.2455 - acc: 0.9186 - val_loss: 0.5620 - val_acc: 0.8225\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.53809\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.2428 - acc: 0.9201 - val_loss: 0.5549 - val_acc: 0.8290\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.53809\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.2348 - acc: 0.9210 - val_loss: 0.5669 - val_acc: 0.8240\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.53809\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.2319 - acc: 0.9235 - val_loss: 0.5651 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.53809\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.2188 - acc: 0.9321 - val_loss: 0.5585 - val_acc: 0.8265\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.53809\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.2162 - acc: 0.9292 - val_loss: 0.5709 - val_acc: 0.8270\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.53809\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.2080 - acc: 0.9337 - val_loss: 0.5828 - val_acc: 0.8215\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.53809\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.2072 - acc: 0.9311 - val_loss: 0.5798 - val_acc: 0.8265\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.53809\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.2019 - acc: 0.9350 - val_loss: 0.5895 - val_acc: 0.8195\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.53809\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.1956 - acc: 0.9366 - val_loss: 0.6058 - val_acc: 0.8205\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.53809\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.1954 - acc: 0.9367 - val_loss: 0.6217 - val_acc: 0.8155\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.53809\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.1877 - acc: 0.9405 - val_loss: 0.6449 - val_acc: 0.8210\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.53809\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.1854 - acc: 0.9407 - val_loss: 0.6110 - val_acc: 0.8240\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.53809\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.1844 - acc: 0.9417 - val_loss: 0.6024 - val_acc: 0.8265\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.53809\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.1805 - acc: 0.9435 - val_loss: 0.6145 - val_acc: 0.8215\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.53809\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.1745 - acc: 0.9475 - val_loss: 0.6175 - val_acc: 0.8205\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.53809\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.1760 - acc: 0.9482 - val_loss: 0.6560 - val_acc: 0.8145\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.53809\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.1726 - acc: 0.9456 - val_loss: 0.6291 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.53809\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.1669 - acc: 0.9484 - val_loss: 0.6276 - val_acc: 0.8225\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.53809\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.1642 - acc: 0.9482 - val_loss: 0.6461 - val_acc: 0.8250\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.53809\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.1661 - acc: 0.9494 - val_loss: 0.6722 - val_acc: 0.8145\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.53809\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.1591 - acc: 0.9522 - val_loss: 0.6528 - val_acc: 0.8240\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.53809\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.1539 - acc: 0.9521 - val_loss: 0.6566 - val_acc: 0.8265\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.53809\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.1567 - acc: 0.9512 - val_loss: 0.6653 - val_acc: 0.8255\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.53809\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.1549 - acc: 0.9509 - val_loss: 0.6649 - val_acc: 0.8190\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.53809\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.1501 - acc: 0.9560 - val_loss: 0.6827 - val_acc: 0.8210\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.53809\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.1483 - acc: 0.9561 - val_loss: 0.6804 - val_acc: 0.8225\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.53809\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.1462 - acc: 0.9545 - val_loss: 0.6917 - val_acc: 0.8235\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.53809\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.1410 - acc: 0.9576 - val_loss: 0.7039 - val_acc: 0.8185\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.53809\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.1451 - acc: 0.9573 - val_loss: 0.7032 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.53809\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.1416 - acc: 0.9576 - val_loss: 0.7173 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.53809\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.1401 - acc: 0.9577 - val_loss: 0.7124 - val_acc: 0.8135\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.53809\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.1398 - acc: 0.9567 - val_loss: 0.7237 - val_acc: 0.8195\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.53809\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.1340 - acc: 0.9594 - val_loss: 0.7306 - val_acc: 0.8165\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.53809\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.1331 - acc: 0.9620 - val_loss: 0.7645 - val_acc: 0.8105\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.53809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe163208790>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint   \n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "input_shape = X_train.shape[1:]\n",
    "inp = Input(shape=input_shape)\n",
    "x = Flatten()(inp)\n",
    "x = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inp, x)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='model.best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "model.fit(X_train, y_train, batch_size=50, epochs=50,\n",
    "          validation_split=0.2, callbacks=[checkpointer],\n",
    "          verbose=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 79us/step\n",
      "Test accuracy: 83.1000%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('model.best.hdf5')\n",
    "\n",
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_val, y_val, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# print test accuracy\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
