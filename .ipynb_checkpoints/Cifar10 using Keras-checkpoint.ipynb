{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as ut\n",
    "import keras\n",
    "import numpy as np\n",
    "import keras.utils as utils\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape is: (30000, 32, 32, 3)\n",
      "x_test shape is: (10000, 32, 32, 3)\n",
      "y_train shape is: (30000, 1)\n",
      "y_test shape is: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train_orig, y_train_orig), (x_test_orig, y_test_orig) = ut.load_data()\n",
    "print \"x_train shape is: \"+str(x_train_orig.shape)\n",
    "print \"x_test shape is: \"+str(x_test_orig.shape)\n",
    "print \"y_train shape is: \"+str(y_train_orig.shape)\n",
    "print \"y_test shape is: \"+str(y_test_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train_orig/255.\n",
    "x_test = x_test_orig/255\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After one hot encoding y_train shape is (30000, 10)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "y_train=utils.to_categorical(y_train_orig,num_classes)\n",
    "y_test=utils.to_categorical(y_test_orig,num_classes)\n",
    "print \"After one hot encoding y_train shape is \"+str(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape):\n",
    "    X_input = Input(input_shape)\n",
    "    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X_input)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2,2),name='pool0')(X)\n",
    "    X = Conv2D(18, (5, 5), strides = (1, 1), name = 'conv1')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2,2),name='pool1')(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(40,name='dense0')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(num_classes)(X)\n",
    "    X = Activation('softmax')(X)\n",
    "    model = Model(inputs = X_input, outputs = X, name='Cifaranalysis')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model made\n"
     ]
    }
   ],
   "source": [
    "CifarModel=model(x_train.shape[1:])\n",
    "print \"Model made\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CifarModel.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 189s 6ms/step - loss: 0.2714 - acc: 0.9008\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 185s 6ms/step - loss: 0.2327 - acc: 0.9105\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 212s 7ms/step - loss: 0.2164 - acc: 0.9163\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 210s 7ms/step - loss: 0.2074 - acc: 0.9198\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 197s 7ms/step - loss: 0.1998 - acc: 0.9229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f547be82fd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CifarModel.fit(x_train,y_train,batch_size=batch_size,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 26s 3ms/step\n",
      "()\n",
      "Loss = 0.20251739666461946\n",
      "Test Accuracy = 0.9208800280570983\n"
     ]
    }
   ],
   "source": [
    "preds = CifarModel.evaluate(x_test,y_test)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Model and it's weight in .h5 format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model to json format and reusing it illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_architecture.json', 'w') as f:\n",
    "    f.write(CifarModel.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "CifarModel.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# Model reconstruction from JSON file\n",
    "with open('model_architecture.json', 'r') as f:\n",
    "    model = model_from_json(f.read())\n",
    "\n",
    "# Load weights into the new model\n",
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating from the loaded model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 28s 3ms/step\n",
      "()\n",
      "Loss = 0.20251739666461946\n",
      "Test Accuracy = 0.9208800280570983\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "preds = model.evaluate(x_test,y_test)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
